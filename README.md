# 100DaysOfMLCode - Part 2

![100 days of ml code](https://cdn-images-1.medium.com/max/1000/1*CnBFqCWTWFWJkcKBa2DWSA.png)

## Overview

These are the instructions for [this](https://www.youtube.com/watch?v=cuQMBj1cWPo&t=7s) video on Youtube by Siraj Raval for the #100DaysofMLCode Challenge. 

## Motivation

Machine Learning is the most transformative technology of our time. Whether its helping us discover new drugs for major diseases,
fighting fraud, generating music, improving supply chain efficiency, the list of applications are truly endless. In order for us as a community
to be able to make valuable contributions to the world, we need to master this technology. This is a call to action, a battle cry, a spark that
will light a movement to radically improve the state of humanity. 100 Days of ML Code is a committment to better your understanding of
this powerful tool by dedicating at least 1 hour of your time everyday to studying and/or coding machine learning for 100 days. 

## Eligibility 

- Everyone is eligible, even people who've never coded before

## The 3 Rules

- Make a public pledge to code or study machine learning for minimum 1 hour every day for the next 100 days via your favorite social platform using the [#100DaysofMLCode](https://twitter.com/sirajraval/status/1014758160572141568) Hashtag.
- Make a public log of your work. Update it daily. Here is a GitHub example [template](https://gist.github.com/llSourcell/43194e486a92532bc343f7837b178eda). Another one is [here](https://github.com/LordSomen/100DaysOfML/blob/master/Log.md). You can also
make a blog or vlog. 
- If you see someone make a post using the #100DaysofMLCode hashtag, encourage them via a 'like', 'share', or comment!

### Day 1: September 1, 2019 

**Today's Progress**: 

* Implemented Supervised learning algorithms : Perceptron, Decision Trees, K Nearest Neighbour, Naive Bayes from Scratch. Learned about Quadratic Discriminant Analyis and Linear Discriminant Analysis in detail. Combined the algorithms to create a web service project.
* Completed Model Validation lecture on Datacamp.
* Completed Convlutional Filters and Edge Detection from Computer Vision Nanodegree.

**Thoughts**: 
* The implementation part of Decision tree was probably the most challenging and the maths behind Naive Bayes will be something I'll never forget. Its yet funny how a perceptron can get almost 100% accuracy on MNIST and 50% on a simple XOR problem.
KNN can be thought of exactly opposite to Naive Bayes had to say.
* Revisited the concepts of manual and grid search, random search model validation techniques.  

**Link(s) to work**:

* [Supervised learning algorithms](https://github.com/sourcecode369/supervised-learning-algorithms)
* [Datacamp](https://campus.datacamp.com/courses/hyperparameter-tuning-in-python/random-search?ex=5)

### Day 2: September 2, 2019 

**Today's Progress**: 
* Started Bayesian Machine Learning by Lazy Programmer. Reached upto Traditional A-B Testing.
* Computer Vision Nanodegree in progress - Implemented Fourier Transform Feature Detector, High and low pass filters, Canny Edge Detector. 

**Thoughts**: 
* Todays progress was slow, though was able to understand all the concepts. Though will try to cope up and learn more tomorrow.

**Link(s) to work**:
* [Bayesian Machine Learning](https://github.com/sourcecode369/bayesian-machine-learning)
* [Computer Vision](https://github.com/sourcecode369/computer-vision)
